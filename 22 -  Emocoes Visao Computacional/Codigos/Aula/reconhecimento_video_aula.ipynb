{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c1f75a3-47dd-4550-83e5-416def0aed9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "476d3d17-2a31-497f-a8cc-46d3932ec5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Carregar o vídeo\n",
    "video_path = \"Material/Videos/video_teste04.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Ler e exibir os frames do vídeo\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1aa1a888-8e4e-45b2-9b81-912e5845ffe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo carregado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Carregar o modelo salvo em formato .h5\n",
    "model = load_model(\"Material/modelo_02_expressoes.h5\")\n",
    "\n",
    "print(\"Modelo carregado com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14a35040-855d-400e-a58b-6fc0aaa6b8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vídeo salvo em: Material/Videos/video_redimensionado.mp4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Configurações de redimensionamento\n",
    "redimensionar = True\n",
    "largura_maxima = 600  # pixels (máxima largura permitida para o vídeo salvo)\n",
    "\n",
    "# Abrir o vídeo\n",
    "video_path = \"Material/Videos/video_teste04.mp4\"\n",
    "video = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not video.isOpened():\n",
    "    print(\"Erro ao abrir o vídeo. Verifique o caminho e o arquivo.\")\n",
    "else:\n",
    "    # Obter dimensões originais do vídeo\n",
    "    largura_original = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    altura_original = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)  # Taxa de quadros do vídeo\n",
    "\n",
    "    # Determinar novas dimensões\n",
    "    if redimensionar and largura_original > largura_maxima:\n",
    "        proporcao = largura_original / altura_original\n",
    "        video_largura = largura_maxima\n",
    "        video_altura = int(video_largura / proporcao)\n",
    "    else:\n",
    "        video_largura = largura_original\n",
    "        video_altura = altura_original\n",
    "\n",
    "    # Configurar o codificador e criar o vídeo de saída\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # Codec para salvar o vídeo\n",
    "    output_path = \"Material/Videos/video_redimensionado.mp4\"\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (video_largura, video_altura))\n",
    "\n",
    "    # Processar e salvar o vídeo\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Redimensionar o frame, se necessário\n",
    "        if redimensionar and largura_original > largura_maxima:\n",
    "            frame = cv2.resize(frame, (video_largura, video_altura), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # Escrever o frame no arquivo de saída\n",
    "        out.write(frame)\n",
    "\n",
    "        # (Opcional) Exibir o frame durante o processamento\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    # Liberar recursos\n",
    "    video.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    print(f\"Vídeo salvo em: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ef38875-1467-48ef-8ed7-6bececf027a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vídeo salvo com sucesso em: Material/Videos/resultado_video_teste04.avi\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Configuração do diretório e nome do arquivo de saída\n",
    "diretorio = 'Material/Videos/'  # Diretório onde o vídeo será salvo\n",
    "os.makedirs(diretorio, exist_ok=True)  # Criar diretório se não existir\n",
    "nome_arquivo = diretorio + 'resultado_video_teste04.avi'\n",
    "\n",
    "# Configurações de redimensionamento\n",
    "redimensionar = True\n",
    "largura_maxima = 600  # Largura máxima em pixels\n",
    "\n",
    "# Abrir o vídeo\n",
    "video_path = \"Material/Videos/video_teste04.mp4\"\n",
    "video = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not video.isOpened():\n",
    "    print(\"Erro ao abrir o vídeo. Verifique o caminho e o arquivo.\")\n",
    "else:\n",
    "    # Obter dimensões originais do vídeo\n",
    "    largura_original = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    altura_original = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)  # Taxa de quadros do vídeo\n",
    "\n",
    "    # Determinar novas dimensões\n",
    "    if redimensionar and largura_original > largura_maxima:\n",
    "        proporcao = largura_original / altura_original\n",
    "        video_largura = largura_maxima\n",
    "        video_altura = int(video_largura / proporcao)\n",
    "    else:\n",
    "        video_largura = largura_original\n",
    "        video_altura = altura_original\n",
    "\n",
    "    # Definição do codec e criação do objeto VideoWriter\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')  # Codec XVID para formato AVI\n",
    "    fps = 24  # Frames por segundo\n",
    "    saida_video = cv2.VideoWriter(nome_arquivo, fourcc, fps, (video_largura, video_altura))\n",
    "\n",
    "    # Processar e salvar o vídeo\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Redimensionar o frame, se necessário\n",
    "        if redimensionar and largura_original > largura_maxima:\n",
    "            frame = cv2.resize(frame, (video_largura, video_altura), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # Escrever o frame no arquivo de saída\n",
    "        saida_video.write(frame)\n",
    "\n",
    "        # (Opcional) Exibir o frame durante o processamento\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    # Liberar recursos\n",
    "    video.release()\n",
    "    saida_video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    print(f\"Vídeo salvo com sucesso em: {nome_arquivo}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d581823-ebf0-4b7b-8ad2-1d6d81f21c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminou\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Caminho para o arquivo Haarcascade\n",
    "haarcascade_faces = diretorio + 'haarcascade_frontalface_alt.xml'\n",
    "\n",
    "# Define os tamanhos para as fontes\n",
    "fonte_pequena, fonte_media = 0.4, 0.7\n",
    "fonte = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "# Lista de expressões faciais\n",
    "expressoes = [\"Raiva\", \"Nojo\", \"Medo\", \"Feliz\", \"Triste\", \"Surpreso\", \"Neutro\"]\n",
    "\n",
    "# Loop para processar cada frame\n",
    "while True:\n",
    "    conectado, frame = cap.read()\n",
    "    \n",
    "    if not conectado:\n",
    "        break  # Se ocorreu um problema ao carregar a imagem, interrompe o programa\n",
    "\n",
    "    t = time.time()  # Tempo atual, antes de iniciar (para calcular o tempo de processamento)\n",
    "    \n",
    "    # Redimensiona o frame se necessário\n",
    "    if redimensionar:\n",
    "        frame = cv2.resize(frame, (video_largura, video_altura)) \n",
    "\n",
    "    # Carrega o Haarcascade para detecção de faces\n",
    "    face_cascade = cv2.CascadeClassifier(haarcascade_faces)\n",
    "    cinza = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Converte para grayscale\n",
    "    faces = face_cascade.detectMultiScale(cinza, scaleFactor=1.2, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Processa cada rosto detectado\n",
    "    if len(faces) > 0:\n",
    "        for (x, y, w, h) in faces:\n",
    "            # Desenha retângulo ao redor da face\n",
    "            frame = cv2.rectangle(frame, (x, y), (x + w, y + h + 10), (255, 50, 50), 2)\n",
    "\n",
    "            # Processa a região de interesse (ROI)\n",
    "            roi = cinza[y:y + h, x:x + w]\n",
    "            roi = cv2.resize(roi, (48, 48))  # Redimensiona para o tamanho das imagens de treinamento\n",
    "            roi = roi.astype(\"float\") / 255.0  # Normaliza\n",
    "            roi = img_to_array(roi)           # Converte para array\n",
    "            roi = np.expand_dims(roi, axis=0) # Adiciona dimensão extra\n",
    "\n",
    "            # Predição - Calcula as probabilidades\n",
    "            result = model.predict(roi)[0]\n",
    "            print(result)\n",
    "\n",
    "            if result is not None:\n",
    "                resultado = np.argmax(result)  # Encontra a emoção com maior probabilidade\n",
    "                cv2.putText(frame, expressoes[resultado], (x, y - 10), fonte, fonte_media, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    # Mostra o tempo de processamento\n",
    "    cv2.putText(frame, \"Frame processado em {:.2f} segundos\".format(time.time() - t), \n",
    "                (20, video_altura - 20), fonte, fonte_pequena, (250, 250, 250), 0, lineType=cv2.LINE_AA)\n",
    "\n",
    "    # Exibe o frame no Jupyter Notebook\n",
    "    _, frame_buffer = cv2.imencode('.jpg', frame)\n",
    "    from IPython.display import display, Image, clear_output\n",
    "    clear_output(wait=True)  # Limpa a saída anterior\n",
    "    display(Image(data=frame_buffer))  # Mostra o frame atual\n",
    "\n",
    "    # Salva o frame no vídeo de saída\n",
    "    saida_video.write(frame)\n",
    "\n",
    "print(\"Terminou\")\n",
    "saida_video.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
